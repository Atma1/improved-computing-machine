{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lK53OaJdvcz",
        "outputId": "aeb58e85-f283-43fd-b814-500c29b371f6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-11 12:00:17.890183: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-10-11 12:00:17.893647: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-10-11 12:00:17.906284: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-11 12:00:17.925574: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-11 12:00:17.930328: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-11 12:00:17.945279: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-10-11 12:00:25.635305: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "from mealpy import Problem, FloatVar, BBO, IntegerVar, GA, StringVar\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from mealpy import GA, PSO, Problem, FloatVar, IntegerVar\n",
        "import numpy as np\n",
        "\n",
        "SEED = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "W-n5DryQHAiV"
      },
      "outputs": [],
      "source": [
        "data = load_breast_cancer()\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "E9trfteaIAP7"
      },
      "outputs": [],
      "source": [
        "class LogisticRegression():\n",
        "    def __init__(self, input: int, optimizer: str, learning_rate: float):\n",
        "        self.input = input\n",
        "        self.optimizer_name = optimizer\n",
        "        self.learning_rate = learning_rate\n",
        "        self.sequential = Sequential([\n",
        "            Input(shape=(input,)),\n",
        "            Dense(1, activation='linear'),\n",
        "        ])\n",
        "\n",
        "    def fit(self, X, y, epochs=50):\n",
        "        self.sequential.compile(\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=getattr(tf.keras.optimizers, self.optimizer_name)(learning_rate=self.learning_rate))\n",
        "        history = self.sequential.fit(X, y, epochs=epochs, verbose=0)\n",
        "        last_loss = history.history[\"loss\"][-1]\n",
        "        return last_loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bd8uni-mpE-Z"
      },
      "outputs": [],
      "source": [
        "class HyperParamProblem(Problem):\n",
        "    def __init__(self, bounds, minmax=\"min\", data=None, **kwargs):\n",
        "        self.data = data\n",
        "\n",
        "        super().__init__(bounds, minmax, **kwargs)\n",
        "\n",
        "    def train_evaluate_model(self, optimizer_name, learning_rate):\n",
        "        input_dim = self.data[\"X_train\"].shape[1]\n",
        "        model = LogisticRegression(input=input_dim, optimizer=optimizer_name, learning_rate=learning_rate)\n",
        "        loss_train = model.fit(self.data[\"X_train\"], self.data[\"y_train\"], epochs=self.data[\"epoch\"])\n",
        "        loss_test = model.sequential.evaluate(self.data[\"X_test\"], self.data[\"y_test\"], verbose=0)\n",
        "\n",
        "        return [loss_train, loss_test]\n",
        "\n",
        "    def obj_func(self, solution):\n",
        "        solution = self.decode_solution(solution)\n",
        "        optimizer_name, learning_rate = solution[\"optimizer\"], solution[\"learning_rate\"]\n",
        "        train_test_loss = self.train_evaluate_model(optimizer_name, learning_rate)\n",
        "        return train_test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "keD1s7ggr6RU"
      },
      "outputs": [],
      "source": [
        "data = {\n",
        "    \"X_train\": X_train,\n",
        "    \"y_train\": y_train,\n",
        "    \"X_test\": X_test,\n",
        "    \"y_test\": y_test,\n",
        "    \"epoch\": 100\n",
        "}\n",
        "optimizers = [ \"SGD\", \"Adam\", \"RMSprop\", \"Adagrad\", \"Adadelta\", \"Adamax\"]\n",
        "bounds = [\n",
        "    StringVar(valid_sets=optimizers, name=\"optimizer\"),\n",
        "    FloatVar(lb=0, ub=0.1, name=\"learning_rate\"),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CU7fC6Fytcol",
        "outputId": "fb489eab-9020-4b12-87aa-95fc6dd267b4"
      },
      "outputs": [],
      "source": [
        "hyperparam_problem = HyperParamProblem(bounds=bounds, minmax=\"min\", data=data, name=\"Hyperparam_problem\", obj_weights=(0.5, 0.5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/10/11 01:05:25 AM, INFO, mealpy.evolutionary_based.GA.BaseGA: Solving 2-objective optimization problem with weights: [0.5 0.5].\n",
            "2024/10/11 01:05:25 AM, WARNING, mealpy.evolutionary_based.GA.BaseGA: The parallel mode: thread is selected. But n_workers is not set. The default n_workers = 4 is used.\n",
            "2024/10/11 01:09:27 AM, INFO, mealpy.evolutionary_based.GA.BaseGA: >>>Problem: Hyperparam_problem, Epoch: 1, Current best: 0.11007980443537235, Global best: 0.11007980443537235, Runtime: 121.94585 seconds\n",
            "2024/10/11 01:11:28 AM, INFO, mealpy.evolutionary_based.GA.BaseGA: >>>Problem: Hyperparam_problem, Epoch: 2, Current best: 0.10327091440558434, Global best: 0.10327091440558434, Runtime: 121.11764 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 16 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x7d15502eb7e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/10/11 01:13:34 AM, INFO, mealpy.evolutionary_based.GA.BaseGA: >>>Problem: Hyperparam_problem, Epoch: 3, Current best: 0.09247362054884434, Global best: 0.09247362054884434, Runtime: 125.24445 seconds\n",
            "2024/10/11 01:15:39 AM, INFO, mealpy.evolutionary_based.GA.BaseGA: >>>Problem: Hyperparam_problem, Epoch: 4, Current best: 0.09684869460761547, Global best: 0.09247362054884434, Runtime: 125.02938 seconds\n",
            "2024/10/11 01:17:41 AM, INFO, mealpy.evolutionary_based.GA.BaseGA: >>>Problem: Hyperparam_problem, Epoch: 5, Current best: 0.10671620070934296, Global best: 0.09247362054884434, Runtime: 122.50920 seconds\n"
          ]
        }
      ],
      "source": [
        "model = PSO.OriginalPSO(epoch=100, pop_size=20, seed=SEED)\n",
        "model_2 = GA.BaseGA(epoch=5, pop_size=50)\n",
        "g_best = model_2.solve(hyperparam_problem, mode='thread')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best agent: id: 1125, target: Objectives: [0.12693752 0.05800972], Fitness: 0.09247362054884434, solution: [3.        0.0238843]\n",
            "Best solution: [3.        0.0238843]\n",
            "Best accuracy: 0.09247362054884434\n",
            "Best parameters: {'optimizer': 'Adamax', 'learning_rate': 0.023884296520883076}\n"
          ]
        }
      ],
      "source": [
        "print(f\"Best agent: {g_best}\")\n",
        "print(f\"Best solution: {g_best.solution}\")\n",
        "print(f\"Best accuracy: {g_best.target.fitness}\")\n",
        "print(f\"Best parameters: {model_2.problem.decode_solution(g_best.solution)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "g_best_pso = model.solve(problem=Problem, mode=\"thread\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/10/11 09:13:42 AM, INFO, mealpy.bio_based.BBO.OriginalBBO: Solving 2-objective optimization problem with weights: [0.5 0.5].\n",
            "2024/10/11 09:16:01 AM, INFO, mealpy.bio_based.BBO.OriginalBBO: >>>Problem: Hyperparam_problem, Epoch: 1, Current best: 0.1008455865085125, Global best: 0.1008455865085125, Runtime: 69.08475 seconds\n",
            "2024/10/11 09:17:10 AM, INFO, mealpy.bio_based.BBO.OriginalBBO: >>>Problem: Hyperparam_problem, Epoch: 2, Current best: 0.09911147691309452, Global best: 0.09911147691309452, Runtime: 69.05036 seconds\n"
          ]
        }
      ],
      "source": [
        "model = BBO.OriginalBBO(epoch=100, pop_size=20, seed=SEED)\n",
        "model.solve(hyperparam_problem)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
