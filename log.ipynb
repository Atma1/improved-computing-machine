{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lK53OaJdvcz",
        "outputId": "aeb58e85-f283-43fd-b814-500c29b371f6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-11 12:00:17.890183: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-10-11 12:00:17.893647: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-10-11 12:00:17.906284: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-11 12:00:17.925574: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-11 12:00:17.930328: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-11 12:00:17.945279: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-10-11 12:00:25.635305: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "from mealpy import Problem, FloatVar, BBO, IntegerVar, GA, StringVar\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from mealpy import GA, PSO, Problem, FloatVar, IntegerVar\n",
        "import numpy as np\n",
        "\n",
        "SEED = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "W-n5DryQHAiV"
      },
      "outputs": [],
      "source": [
        "data = load_breast_cancer()\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "E9trfteaIAP7"
      },
      "outputs": [],
      "source": [
        "class LogisticRegression():\n",
        "    def __init__(self, input: int, optimizer: str, learning_rate: float):\n",
        "        self.input = input\n",
        "        self.optimizer_name = optimizer\n",
        "        self.learning_rate = learning_rate\n",
        "        self.sequential = Sequential([\n",
        "            Input(shape=(input,)),\n",
        "            Dense(1, activation='linear'),\n",
        "        ])\n",
        "\n",
        "    def fit(self, X, y, epochs=50):\n",
        "        self.sequential.compile(\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=getattr(tf.keras.optimizers, self.optimizer_name)(learning_rate=self.learning_rate))\n",
        "        history = self.sequential.fit(X, y, epochs=epochs, verbose=0)\n",
        "        last_loss = history.history[\"loss\"][-1]\n",
        "        return last_loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bd8uni-mpE-Z"
      },
      "outputs": [],
      "source": [
        "class HyperParamProblem(Problem):\n",
        "    def __init__(self, bounds, minmax=\"min\", data=None, **kwargs):\n",
        "        self.data = data\n",
        "\n",
        "        super().__init__(bounds, minmax, **kwargs)\n",
        "\n",
        "    def train_evaluate_model(self, optimizer_name, learning_rate):\n",
        "        input_dim = self.data[\"X_train\"].shape[1]\n",
        "        model = LogisticRegression(input=input_dim, optimizer=optimizer_name, learning_rate=learning_rate)\n",
        "        loss_train = model.fit(self.data[\"X_train\"], self.data[\"y_train\"], epochs=self.data[\"epoch\"])\n",
        "        loss_test = model.sequential.evaluate(self.data[\"X_test\"], self.data[\"y_test\"], verbose=0)\n",
        "\n",
        "        return [loss_train, loss_test]\n",
        "\n",
        "    def obj_func(self, solution):\n",
        "        solution = self.decode_solution(solution)\n",
        "        optimizer_name, learning_rate = solution[\"optimizer\"], solution[\"learning_rate\"]\n",
        "        train_test_loss = self.train_evaluate_model(optimizer_name, learning_rate)\n",
        "        return train_test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "keD1s7ggr6RU"
      },
      "outputs": [],
      "source": [
        "data = {\n",
        "    \"X_train\": X_train,\n",
        "    \"y_train\": y_train,\n",
        "    \"X_test\": X_test,\n",
        "    \"y_test\": y_test,\n",
        "    \"epoch\": 100\n",
        "}\n",
        "optimizers = [ \"SGD\", \"Adam\", \"RMSprop\", \"Adagrad\", \"Adadelta\", \"Adamax\"]\n",
        "bounds = [\n",
        "    StringVar(valid_sets=optimizers, name=\"optimizer\"),\n",
        "    FloatVar(lb=0, ub=0.1, name=\"learning_rate\"),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CU7fC6Fytcol",
        "outputId": "fb489eab-9020-4b12-87aa-95fc6dd267b4"
      },
      "outputs": [],
      "source": [
        "hyperparam_problem = HyperParamProblem(bounds=bounds, minmax=\"min\", data=data, name=\"Hyperparam_problem\", obj_weights=(0.5, 0.5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/10/11 12:02:20 PM, INFO, mealpy.evolutionary_based.GA.BaseGA: Solving 2-objective optimization problem with weights: [0.5 0.5].\n",
            "2024/10/11 12:02:20 PM, WARNING, mealpy.evolutionary_based.GA.BaseGA: The parallel mode: thread is selected. But n_workers is not set. The default n_workers = 4 is used.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 14 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x751a992d7100> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/10/11 12:06:29 PM, INFO, mealpy.evolutionary_based.GA.BaseGA: >>>Problem: Hyperparam_problem, Epoch: 1, Current best: 0.10121588036417961, Global best: 0.10121588036417961, Runtime: 125.07289 seconds\n",
            "2024/10/11 12:08:31 PM, INFO, mealpy.evolutionary_based.GA.BaseGA: >>>Problem: Hyperparam_problem, Epoch: 2, Current best: 0.10421675443649292, Global best: 0.10121588036417961, Runtime: 122.62916 seconds\n",
            "2024/10/11 12:10:37 PM, INFO, mealpy.evolutionary_based.GA.BaseGA: >>>Problem: Hyperparam_problem, Epoch: 3, Current best: 0.08724456839263439, Global best: 0.08724456839263439, Runtime: 126.02542 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 14 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x751a73419e40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/10/11 12:12:47 PM, INFO, mealpy.evolutionary_based.GA.BaseGA: >>>Problem: Hyperparam_problem, Epoch: 4, Current best: 0.09867200814187527, Global best: 0.08724456839263439, Runtime: 130.17507 seconds\n",
            "2024/10/11 12:14:51 PM, INFO, mealpy.evolutionary_based.GA.BaseGA: >>>Problem: Hyperparam_problem, Epoch: 5, Current best: 0.09203901328146458, Global best: 0.08724456839263439, Runtime: 123.57800 seconds\n"
          ]
        }
      ],
      "source": [
        "ga_model = GA.BaseGA(epoch=5, pop_size=50)\n",
        "ga_best = ga_model.solve(hyperparam_problem, mode='thread')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best agent: id: 566, target: Objectives: [0.11708042 0.05740872], Fitness: 0.08724456839263439, solution: [3.         0.02384694]\n",
            "Best solution: [3.         0.02384694]\n",
            "Best accuracy: 0.08724456839263439\n",
            "Best parameters: {'optimizer': 'Adamax', 'learning_rate': 0.023846939637753486}\n"
          ]
        }
      ],
      "source": [
        "print(f\"Best agent: {ga_best}\")\n",
        "print(f\"Best solution: {ga_best.solution}\")\n",
        "print(f\"Best accuracy: {ga_best.target.fitness}\")\n",
        "print(f\"Best parameters: {ga_model.problem.decode_solution(ga_best.solution)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/10/11 12:14:51 PM, INFO, mealpy.bio_based.BBO.OriginalBBO: Solving 2-objective optimization problem with weights: [0.5 0.5].\n",
            "2024/10/11 12:14:51 PM, WARNING, mealpy.bio_based.BBO.OriginalBBO: The parallel mode: thread is selected. But n_workers is not set. The default n_workers = 4 is used.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/10/11 12:16:27 PM, INFO, mealpy.bio_based.BBO.OriginalBBO: >>>Problem: Hyperparam_problem, Epoch: 1, Current best: 0.12737616151571274, Global best: 0.12737616151571274, Runtime: 48.28135 seconds\n",
            "2024/10/11 12:17:14 PM, INFO, mealpy.bio_based.BBO.OriginalBBO: >>>Problem: Hyperparam_problem, Epoch: 2, Current best: 0.10119216702878475, Global best: 0.10119216702878475, Runtime: 47.57103 seconds\n",
            "2024/10/11 12:18:02 PM, INFO, mealpy.bio_based.BBO.OriginalBBO: >>>Problem: Hyperparam_problem, Epoch: 3, Current best: 0.10119216702878475, Global best: 0.10119216702878475, Runtime: 47.93851 seconds\n",
            "2024/10/11 12:18:52 PM, INFO, mealpy.bio_based.BBO.OriginalBBO: >>>Problem: Hyperparam_problem, Epoch: 4, Current best: 0.10116437450051308, Global best: 0.10116437450051308, Runtime: 49.25821 seconds\n",
            "2024/10/11 12:19:39 PM, INFO, mealpy.bio_based.BBO.OriginalBBO: >>>Problem: Hyperparam_problem, Epoch: 5, Current best: 0.10116437450051308, Global best: 0.10116437450051308, Runtime: 47.64880 seconds\n"
          ]
        }
      ],
      "source": [
        "bbo_model = BBO.OriginalBBO(epoch=5, pop_size=20, seed=SEED)\n",
        "bbo_best = bbo_model.solve(hyperparam_problem, mode=\"thread\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best agent: id: 728, target: Objectives: [0.14003725 0.0622915 ], Fitness: 0.10116437450051308, solution: [3.         0.01025408]\n",
            "Best solution: [3.         0.01025408]\n",
            "Best accuracy: 0.10116437450051308\n",
            "Best parameters: {'optimizer': 'Adamax', 'learning_rate': 0.01025407665488003}\n"
          ]
        }
      ],
      "source": [
        "print(f\"Best agent: {bbo_best}\")\n",
        "print(f\"Best solution: {bbo_best.solution}\")\n",
        "print(f\"Best accuracy: {bbo_best.target.fitness}\")\n",
        "print(f\"Best parameters: {bbo_model.problem.decode_solution(bbo_best.solution)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_solution = ga_model.problem.decode_solution(ga_best.solution) if bbo_best.target.fitness < ga_best.target.fitness else bbo_model.problem.decode_solution(bbo_best.solution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'optimizer': 'Adamax', 'learning_rate': 0.01025407665488003}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_solution"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
